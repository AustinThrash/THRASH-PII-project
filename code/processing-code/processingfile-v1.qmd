---
title: "An example cleaning script"
author: "Andreas Handel"
date: "2024-02-07"
output: html_document
---


# Processing script

This contains the same code and comments/information as `processingcode.R`.

This just shows it as Quarto file, to give you an idea how to do it in a setup that combines code and text in a single file.

See the other Quarto file for my currently preferred approach of pulling code from the R script into the Quarto file.


# Setup

Load needed packages. make sure they are installed.

```{r}
library(readxl) #for loading Excel files
library(dplyr) #for data processing/cleaning
library(tidyr) #for data processing/cleaning
library(skimr) #for nice visualization of data 
library(here) #to set paths
```


# Data loading

Note that for functions that come from specific packages (instead of base R), I often specify both package and function like so:
package::function() that's not required one could just call the function specifying the package makes it clearer where the function "lives",
but it adds typing. You can do it either way.

```{r}
# path to data
# note the use of the here() package and not absolute paths
data_location <- here::here("data","raw-data","diabetes.csv")
rawdata <- read.csv(data_location)
```


# Check data

Several ways of looking at the data

```{r}
dplyr::glimpse(rawdata)
summary(rawdata)
head(rawdata)
skimr::skim(rawdata)
```



# Cleaning

This data set was cleaned prior to upload online, from reviewing the data, it does not seem any further cleaning or processing is required.


# Save data 


```{r}
save_data_location <- here::here("data","processed-data","processeddata.rds")
saveRDS(rawdata, file = save_data_location)
```



# Notes

Removing anyone who had "faulty" or missing data is one approach. It's often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep individuals with some missing information).

